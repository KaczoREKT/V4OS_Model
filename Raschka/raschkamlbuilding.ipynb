{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"initial_id\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-12-03T12:58:51.990303Z\",\n",
    "     \"start_time\": \"2025-12-03T12:58:51.981481Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"import tiktoken\\n\",\n",
    "    \"\\n\",\n",
    "    \"tokenizer = tiktoken.get_encoding(\\\"gpt2\\\")\\n\",\n",
    "    \"text = (\\\"Hello, do you like tea <|endoftext|> In the sunlit terraces\\\")\\n\",\n",
    "    \"integers = tokenizer.encode(text, allowed_special={\\\"<|endoftext|>\\\"})\\n\",\n",
    "    \"print(integers)\\n\",\n",
    "    \"strings = tokenizer.decode(integers)\\n\",\n",
    "    \"print(strings)\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[15496, 11, 466, 345, 588, 8887, 220, 50256, 554, 262, 4252, 18250, 8812, 2114]\\n\",\n",
    "      \"Hello, do you like tea <|endoftext|> In the sunlit terraces\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-12-03T12:58:56.422006Z\",\n",
    "     \"start_time\": \"2025-12-03T12:58:52.004529Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class GPTDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, txt, tokenizer, max_length, stride):\\n\",\n",
    "    \"        self.input_ids = []\\n\",\n",
    "    \"        self.target_ids = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"        token_ids = tokenizer.encode(txt)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for i in range(0, len(token_ids) - max_length, stride):\\n\",\n",
    "    \"            input_chunk = token_ids[i:i + max_length]\\n\",\n",
    "    \"            target_chunk = token_ids[i + 1: i + max_length + 1]\\n\",\n",
    "    \"            self.input_ids.append(torch.tensor(input_chunk))\\n\",\n",
    "    \"            self.target_ids.append(torch.tensor(target_chunk))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return len(self.input_ids)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        return self.input_ids[idx], self.target_ids[idx]\"\n",
    "   ],\n",
    "   \"id\": \"88d314d619b62172\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 7\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-12-03T12:58:56.440116Z\",\n",
    "     \"start_time\": \"2025-12-03T12:58:56.437595Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def create_dataloader(txt, batch_size=4, max_length=256,\\n\",\n",
    "    \"                      stride=128, shuffle=True, drop_last=True,\\n\",\n",
    "    \"                      num_workers=0):\\n\",\n",
    "    \"    tokenizer = tiktoken.get_encoding(\\\"gpt2\\\")\\n\",\n",
    "    \"    dataset = GPTDataset(txt, tokenizer, max_length, stride)\\n\",\n",
    "    \"    dataloader = DataLoader(\\n\",\n",
    "    \"        dataset,\\n\",\n",
    "    \"        batch_size=batch_size,\\n\",\n",
    "    \"        shuffle=shuffle,\\n\",\n",
    "    \"        drop_last=drop_last,\\n\",\n",
    "    \"        num_workers=num_workers\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    return dataloader\"\n",
    "   ],\n",
    "   \"id\": \"419dab2bda48847a\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 8\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-12-03T12:58:56.608405Z\",\n",
    "     \"start_time\": \"2025-12-03T12:58:56.454665Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"with open(\\\"the-verdict.txt\\\", \\\"r\\\", encoding=\\\"utf-8\\\") as f:\\n\",\n",
    "    \"    txt = f.read()\\n\",\n",
    "    \"dataloader = create_dataloader(txt, batch_size=1, shuffle=False, max_length=4, stride=1)\\n\",\n",
    "    \"data_iter = iter(dataloader)\\n\",\n",
    "    \"first_batch = next(data_iter)\\n\",\n",
    "    \"print(first_batch)\"\n",
    "   ],\n",
    "   \"id\": \"d6997b68d48396cf\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 9\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-12-03T13:02:40.293400Z\",\n",
    "     \"start_time\": \"2025-12-03T13:02:40.255415Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"vocab_size = 6\\n\",\n",
    "    \"output_dim = 3\\n\",\n",
    "    \"torch.manual_seed(123)\\n\",\n",
    "    \"embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\\n\",\n",
    "    \"print(embedding_layer.weight)\"\n",
    "   ],\n",
    "   \"id\": \"d4775e0d36ab7937\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Parameter containing:\\n\",\n",
    "      \"tensor([[ 0.3374, -0.1778, -0.1690],\\n\",\n",
    "      \"        [ 0.9178,  1.5810,  1.3010],\\n\",\n",
    "      \"        [ 1.2753, -0.2010, -0.1606],\\n\",\n",
    "      \"        [-0.4015,  0.9666, -1.1481],\\n\",\n",
    "      \"        [-1.1589,  0.3255, -0.6315],\\n\",\n",
    "      \"        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 10\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "ee116b6cf90448a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
