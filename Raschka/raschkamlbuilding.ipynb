{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T11:39:54.489479Z",
     "start_time": "2025-12-05T11:39:54.327062Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = (\"Hello, do you like tea <|endoftext|> In the sunlit terraces\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 220, 50256, 554, 262, 4252, 18250, 8812, 2114]\n",
      "Hello, do you like tea <|endoftext|> In the sunlit terraces\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:39:55.547824Z",
     "start_time": "2025-12-05T11:39:54.500715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ],
   "id": "88d314d619b62172",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:39:55.557006Z",
     "start_time": "2025-12-05T11:39:55.554780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader(txt, batch_size=4, max_length=256,\n",
    "                      stride=128, shuffle=True, drop_last=True,\n",
    "                      num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ],
   "id": "419dab2bda48847a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:39:55.620186Z",
     "start_time": "2025-12-05T11:39:55.567901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()\n",
    "dataloader = create_dataloader(txt, batch_size=1, shuffle=False, max_length=4, stride=1)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ],
   "id": "d6997b68d48396cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:39:55.646528Z",
     "start_time": "2025-12-05T11:39:55.629259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ],
   "id": "d4775e0d36ab7937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:34:26.471734Z",
     "start_time": "2025-12-05T12:34:26.461369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor([[ 0.3374, -0.1778, -0.1690],\n",
    "        [ 0.9178,  1.5810,  1.3010],\n",
    "        [ 1.2753, -0.2010, -0.1606],\n",
    "        [-0.4015,  0.9666, -1.1481],\n",
    "        [-1.1589,  0.3255, -0.6315],\n",
    "        [-2.8400, -0.7849, -1.4096]]\n",
    ")"
   ],
   "id": "2cbeefc4c882e57b",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:35:17.784823Z",
     "start_time": "2025-12-05T12:35:17.778899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)"
   ],
   "id": "83b931f028cad059",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1913,  5.0345,  0.6437, -0.3340, -1.3706, -5.6814])\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:34:31.801463Z",
     "start_time": "2025-12-05T12:34:31.793659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = 0\n",
    "for idx, element in enumerate(inputs[0]):\n",
    "    res += inputs[0][idx] * query[idx]\n",
    "print(res)\n",
    "print(torch.dot(inputs[0], query))"
   ],
   "id": "b4b8ccc787cce940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1913)\n",
      "tensor(-0.1913)\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:07:02.387790Z",
     "start_time": "2025-12-05T12:07:02.373503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(f\"Attention weights: {attn_weights_2_tmp}\")\n",
    "print(f\"Attention weights sum: {attn_weights_2_tmp.sum():.2f}\")"
   ],
   "id": "7bc8c7690ea5413a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([ 0.1007, -2.6512, -0.3390,  0.1759,  0.7218,  2.9918])\n",
      "Attention weights sum: 1.00\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:09:21.629474Z",
     "start_time": "2025-12-05T12:09:21.615272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "print(softmax_naive(attn_scores_2))\n",
    "print(softmax_naive(attn_scores_2).sum())"
   ],
   "id": "935a834864d5e957",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.2494e-03, 9.7646e-01, 1.2100e-02, 4.5514e-03, 1.6142e-03, 2.1667e-05])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:35:30.676240Z",
     "start_time": "2025-12-05T12:35:30.657603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(attn_weights_2)\n",
    "print(attn_weights_2.sum())"
   ],
   "id": "78a49f8381c7c66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.2494e-03, 9.7646e-01, 1.2100e-02, 4.5514e-03, 1.6142e-03, 2.1667e-05])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:34:36.967072Z",
     "start_time": "2025-12-05T12:34:36.959275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(context_vec_2)\n"
   ],
   "id": "96dcfcd9f631864e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9096, 1.5453, 1.2613])\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:34:38.499652Z",
     "start_time": "2025-12-05T12:34:38.493945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_scores = torch.empty(6,6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, y_j in enumerate(inputs):\n",
    "        attn_scores[i,j] = torch.dot(x_i, y_j)\n",
    "print(attn_scores)"
   ],
   "id": "e16a43e8abc36e38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1740, -0.1913,  0.4932, -0.1133, -0.3422, -0.5804],\n",
      "        [-0.1913,  5.0345,  0.6437, -0.3340, -1.3706, -5.6814],\n",
      "        [ 0.4932,  0.6437,  1.6926, -0.5219, -1.4420, -3.2377],\n",
      "        [-0.1133, -0.3340, -0.5219,  2.4137,  1.5050,  1.9999],\n",
      "        [-0.3422, -1.3706, -1.4420,  1.5050,  1.8478,  3.9260],\n",
      "        [-0.5804, -5.6814, -3.2377,  1.9999,  3.9260, 10.6686]])\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:29:07.412950Z",
     "start_time": "2025-12-05T12:29:07.406218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ],
   "id": "c989e2b1d88ee91f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1740, -0.1913,  0.4932, -0.1133, -0.3422, -0.5804],\n",
      "        [-0.1913,  5.0345,  0.6437, -0.3340, -1.3706, -5.6814],\n",
      "        [ 0.4932,  0.6437,  1.6926, -0.5219, -1.4420, -3.2377],\n",
      "        [-0.1133, -0.3340, -0.5219,  2.4137,  1.5050,  1.9999],\n",
      "        [-0.3422, -1.3706, -1.4420,  1.5050,  1.8478,  3.9260],\n",
      "        [-0.5804, -5.6814, -3.2377,  1.9999,  3.9260, 10.6686]])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:34:02.847870Z",
     "start_time": "2025-12-05T12:34:02.840864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)\n",
    "print(attn_weights.sum(dim=-1))"
   ],
   "id": "75e45dda418eb2a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0461e-01, 1.4200e-01, 2.8154e-01, 1.5352e-01, 1.2211e-01, 9.6223e-02],\n",
      "        [5.2494e-03, 9.7646e-01, 1.2100e-02, 4.5514e-03, 1.6142e-03, 2.1667e-05],\n",
      "        [1.6635e-01, 1.9338e-01, 5.5198e-01, 6.0279e-02, 2.4022e-02, 3.9877e-03],\n",
      "        [3.5334e-02, 2.8337e-02, 2.3482e-02, 4.4222e-01, 1.7824e-01, 2.9239e-01],\n",
      "        [1.1318e-02, 4.0470e-03, 3.7683e-03, 7.1774e-02, 1.0113e-01, 8.0797e-01],\n",
      "        [1.3002e-05, 7.9193e-08, 9.1192e-07, 1.7165e-04, 1.1779e-03, 9.9864e-01]])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T12:39:27.509902Z",
     "start_time": "2025-12-05T12:39:27.495568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)\n",
    "print(context_vec_2)"
   ],
   "id": "16d35bedf5c68d7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0820,  0.2441, -0.2841],\n",
      "        [ 0.9096,  1.5453,  1.2613],\n",
      "        [ 0.8742,  0.2282,  0.0448],\n",
      "        [-1.1466,  0.2898, -1.0053],\n",
      "        [-2.4283, -0.5283, -1.2824],\n",
      "        [-2.8376, -0.7833, -1.4086]])\n",
      "tensor([0.9096, 1.5453, 1.2613])\n"
     ]
    }
   ],
   "execution_count": 92
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
